---
title: "Subject_Analysis"
output: html_document
---

Load up the data

```{r set up libraries}
library(ggplot2)
library(plyr)
library(lme4)

lagpad <- function(x, k,df) {
    if (!is.vector(x)) 
        stop('x must be a vector')
    if (!is.numeric(x)) 
        stop('x must be numeric')
    if (!is.numeric(k))
        stop('k must be numeric')
    if (1 != length(k))
        stop('k must be a single number')
    vec = c(rep(NA, k), x)[1 : length(x)] 
    vec[df$X<k]=NA
    return(vec)
}
```

```{r Load data}
  learner = read.csv('Analysis_Output/learners.csv')
  nonlearner = read.csv('Analysis_Output/nonlearners.csv')
```


```{r}
rs1 = glmer(subj_ts ~ context + 
              last_TS + (last_TS + context + 1 | id), data = learner, family = binomial)
summary(rs1) 

rs2 = glmer(subj_ts ~ context + 
              last_TS + (last_TS + context + 1 | id), data = nonlearner, family = binomial)
summary(rs2) 

rs3 = glmer(subj_ts ~ context + last_TS +
              lagpad(context,1,learner) + 
              lagpad(context,2,learner) + 
              lagpad(context,3,learner) + 
              lagpad(context,4,learner) + 
              lagpad(context,5,learner) + 
              (lagpad(context,1,learner)+ context + 1 | id),
            data = learner, family = binomial)
summary(rs3) 

rs4 = glmer(subj_ts ~ context + 
              lagpad(context,1,nonlearner) + 
              lagpad(context,2,nonlearner) + 
              lagpad(context,3,nonlearner) + 
              lagpad(context,4,nonlearner) + 
              lagpad(context,5,nonlearner) + 
              (lagpad(context,1,nonlearner) +
               + context + 1 | id),
            data = nonlearner, family = binomial)
summary(rs4) 
```

```{r}
  learner$log_rt = log(learner$rt)
  rs5 = lmer(log_rt ~ bias2_certainty + (1+bias2_certainty | id), data = learner)
  summary(rs5)
```

```{r}
  rt_df = gtest_learn_df
  rt_df$subj_switch = as.factor(rt_df$subj_switch)
  summary(lmer(log_rt ~ subj_switch + rep_resp + (1 + subj_switch +rep_resp | id), data = rt_df))
  summary(lmer(log_rt ~ subj_switch + rep_resp + (1 + subj_switch +rep_resp | id), data = rt_df))

  rt_df$abs_context_diff = abs(rt_df$context_diff)
  summary(lmer(log_rt ~ subj_switch + rep_resp + abs_context_diff + (1 + subj_switch +rep_resp + abs_context_diff | id), data = rt_df))
```

```{r Model certainty vs rt}
#Plot rt against optimal model certainty
plot_df = gtest_learn_df
ggplot(data = plot_df, aes(bias2_certainty, log_rt, color = id)) + geom_point() + geom_smooth(method = 'lm')

rs1 = lmer(log_rt ~ bias2_certainty + (1 + bias2_certainty|id), data = gtest_learn_df)
summary(rs1) 

rs2 = lm(log_rt ~ 1+ bias2_certainty, data = gtest_learn_df)
summary(rs2) 

```

```{r}
  sum((gtest_learn_df$subj_ts-gtest_learn_df$fit_observer_posterior)/(gtest_learn_df$fit_observer_posterior*(1-gtest_learn_df$fit_observer_posterior))^.5)
```

